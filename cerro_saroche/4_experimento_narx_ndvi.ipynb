{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variación espacio-temporal precipitación total\n",
    "\n",
    "**PROYECTO:** SISTEMA PARA EL SEGUIMIENTO DE ECOSISTEMAS VENEZOLANOS \\\n",
    "**AUTOR:** Javier Martinez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Directorio actual:  /media/javier/Compartida/doctorado/ssev-analytics/cerro_saroche\n",
      "> Directorio actual:  /media/javier/Compartida/doctorado/ssev-analytics\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print('> Directorio actual: ', os.getcwd())  \n",
    "os.chdir('../')\n",
    "print('> Directorio actual: ', os.getcwd()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from utils.MONGO import CONEXION\n",
    "from utils.UTILS import *\n",
    "from datetime import datetime\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conexión MongoDB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['meteorological', 'estimateSSTNino34', 'SSTNino34']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creando la conexión con MongoDB\n",
    "db = CONEXION.conexion()\n",
    "db.list_collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parque\n",
    "park = 'cerro_saroche'#sys.argv[1]\n",
    "id_point = 1#int(sys.argv[2])\n",
    "\n",
    "y_output = 'ndvi_t'#sys.argv[3]\n",
    "exogena = 'precipitation_ann_t'#sys.argv[4]\n",
    "\n",
    "prediction_order = 2*24#int(sys.argv[5])# rango de prediccion\n",
    "auto_order = 2*12#int(sys.argv[6]) # componente autoregresiva\n",
    "exog_order = 2*12#int(sys.argv[7])# componente exogena qm\n",
    "exog_delay = 0#int(sys.argv[8])# componente exogena dm\n",
    "\n",
    "f_activation = 'sigmoid'#sys.argv[9]\n",
    "\n",
    "# Parametros de modelos\n",
    "patience = 15\n",
    "epochs=500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descargando información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>id_point</th>\n",
       "      <th>park</th>\n",
       "      <th>time</th>\n",
       "      <th>elevacion_maxima</th>\n",
       "      <th>elevacion_media</th>\n",
       "      <th>elevacion_mediana</th>\n",
       "      <th>latitud</th>\n",
       "      <th>longitud</th>\n",
       "      <th>ndvi_maxima</th>\n",
       "      <th>ndvi_media</th>\n",
       "      <th>ndvi_mediana</th>\n",
       "      <th>precipitacion_mm</th>\n",
       "      <th>time_actualizacion</th>\n",
       "      <th>periodo</th>\n",
       "      <th>mes_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>633988a2eed0e0231b327c97</td>\n",
       "      <td>1</td>\n",
       "      <td>cerro_saroche</td>\n",
       "      <td>719163</td>\n",
       "      <td>921.0</td>\n",
       "      <td>508.541046</td>\n",
       "      <td>491.0</td>\n",
       "      <td>10.31</td>\n",
       "      <td>-69.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.913065</td>\n",
       "      <td>738430</td>\n",
       "      <td>1970-01-01</td>\n",
       "      <td>January-1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>633988a3eed0e0231b327d98</td>\n",
       "      <td>1</td>\n",
       "      <td>cerro_saroche</td>\n",
       "      <td>719194</td>\n",
       "      <td>921.0</td>\n",
       "      <td>508.541046</td>\n",
       "      <td>491.0</td>\n",
       "      <td>10.31</td>\n",
       "      <td>-69.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.081278</td>\n",
       "      <td>738430</td>\n",
       "      <td>1970-02-01</td>\n",
       "      <td>February-1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>633988a4eed0e0231b327e91</td>\n",
       "      <td>1</td>\n",
       "      <td>cerro_saroche</td>\n",
       "      <td>719222</td>\n",
       "      <td>921.0</td>\n",
       "      <td>508.541046</td>\n",
       "      <td>491.0</td>\n",
       "      <td>10.31</td>\n",
       "      <td>-69.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.413783</td>\n",
       "      <td>738430</td>\n",
       "      <td>1970-03-01</td>\n",
       "      <td>March-1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>633988a5eed0e0231b327f98</td>\n",
       "      <td>1</td>\n",
       "      <td>cerro_saroche</td>\n",
       "      <td>719253</td>\n",
       "      <td>921.0</td>\n",
       "      <td>508.541046</td>\n",
       "      <td>491.0</td>\n",
       "      <td>10.31</td>\n",
       "      <td>-69.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.895653</td>\n",
       "      <td>738430</td>\n",
       "      <td>1970-04-01</td>\n",
       "      <td>April-1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>633988a6eed0e0231b328114</td>\n",
       "      <td>1</td>\n",
       "      <td>cerro_saroche</td>\n",
       "      <td>719283</td>\n",
       "      <td>921.0</td>\n",
       "      <td>508.541046</td>\n",
       "      <td>491.0</td>\n",
       "      <td>10.31</td>\n",
       "      <td>-69.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.909450</td>\n",
       "      <td>738430</td>\n",
       "      <td>1970-05-01</td>\n",
       "      <td>May-1970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  id_point           park    time  \\\n",
       "0  633988a2eed0e0231b327c97         1  cerro_saroche  719163   \n",
       "1  633988a3eed0e0231b327d98         1  cerro_saroche  719194   \n",
       "2  633988a4eed0e0231b327e91         1  cerro_saroche  719222   \n",
       "3  633988a5eed0e0231b327f98         1  cerro_saroche  719253   \n",
       "4  633988a6eed0e0231b328114         1  cerro_saroche  719283   \n",
       "\n",
       "   elevacion_maxima  elevacion_media  elevacion_mediana  latitud  longitud  \\\n",
       "0             921.0       508.541046              491.0    10.31    -69.83   \n",
       "1             921.0       508.541046              491.0    10.31    -69.83   \n",
       "2             921.0       508.541046              491.0    10.31    -69.83   \n",
       "3             921.0       508.541046              491.0    10.31    -69.83   \n",
       "4             921.0       508.541046              491.0    10.31    -69.83   \n",
       "\n",
       "   ndvi_maxima  ndvi_media  ndvi_mediana  precipitacion_mm  \\\n",
       "0          NaN         NaN           NaN          0.913065   \n",
       "1          NaN         NaN           NaN          0.081278   \n",
       "2          NaN         NaN           NaN          0.413783   \n",
       "3          NaN         NaN           NaN          0.895653   \n",
       "4          NaN         NaN           NaN          2.909450   \n",
       "\n",
       "   time_actualizacion    periodo       mes_year  \n",
       "0              738430 1970-01-01   January-1970  \n",
       "1              738430 1970-02-01  February-1970  \n",
       "2              738430 1970-03-01     March-1970  \n",
       "3              738430 1970-04-01     April-1970  \n",
       "4              738430 1970-05-01       May-1970  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Realizando consulta\n",
    "meteorological = db.meteorological.find({\"park\":park, 'id_point':id_point})\n",
    "\n",
    "# Generando pandas dataframe\n",
    "data_pandas = pd.DataFrame([file for file in meteorological])\n",
    "data_pandas['periodo'] = data_pandas.time.apply(lambda x: datetime.fromordinal(x))\n",
    "data_pandas['mes_year'] =  data_pandas['periodo'].dt.strftime('%B-%Y')\n",
    "#data_pandas.index = pd.to_datetime(data_pandas.periodo)\n",
    "\n",
    "data_pandas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012-01-01 00:00:00\n",
      "2022-05-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(data_pandas[data_pandas.ndvi_media.notnull()].periodo.min())\n",
    "print((data_pandas[data_pandas.ndvi_media.notnull()].periodo.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_point</th>\n",
       "      <th>latitud</th>\n",
       "      <th>longitud</th>\n",
       "      <th>ndvi_media</th>\n",
       "      <th>periodo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.31</td>\n",
       "      <td>-69.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1970-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10.31</td>\n",
       "      <td>-69.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1970-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10.31</td>\n",
       "      <td>-69.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1970-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>10.31</td>\n",
       "      <td>-69.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1970-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>10.31</td>\n",
       "      <td>-69.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1970-05-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_point  latitud  longitud  ndvi_media    periodo\n",
       "0         1    10.31    -69.83         NaN 1970-01-01\n",
       "1         1    10.31    -69.83         NaN 1970-02-01\n",
       "2         1    10.31    -69.83         NaN 1970-03-01\n",
       "3         1    10.31    -69.83         NaN 1970-04-01\n",
       "4         1    10.31    -69.83         NaN 1970-05-01"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_interpolate = []\n",
    "\n",
    "for id in data_pandas.sort_values('id_point',ascending=True).id_point.unique():\n",
    "\n",
    "    pd_interpolate = data_pandas[[ 'id_point', 'latitud', \n",
    "                                'longitud', 'ndvi_media','periodo']]\\\n",
    "                                .query(f'id_point=={id}')\\\n",
    "                                .sort_values('periodo',ascending=True)\n",
    "\n",
    "    pd_interpolate['ndvi_media'] = pd_interpolate['ndvi_media'].interpolate(method=\"linear\")\n",
    "\n",
    "    list_interpolate.append(pd_interpolate)\n",
    "\n",
    "pd_ndvi = pd.concat(list_interpolate)\n",
    "\n",
    "pd_ndvi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargando la data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>park</th>\n",
       "      <th>periodo</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>id_point</th>\n",
       "      <th>latitud</th>\n",
       "      <th>longitud</th>\n",
       "      <th>type</th>\n",
       "      <th>precipitacion_mm</th>\n",
       "      <th>elevacion_media</th>\n",
       "      <th>precipitacion_narx</th>\n",
       "      <th>prediction_ann</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cerro_saroche</td>\n",
       "      <td>1995-02-01</td>\n",
       "      <td>1995</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10.31</td>\n",
       "      <td>-69.83</td>\n",
       "      <td>training</td>\n",
       "      <td>0.340843</td>\n",
       "      <td>508.541046</td>\n",
       "      <td>0.355879</td>\n",
       "      <td>0.332924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cerro_saroche</td>\n",
       "      <td>1995-03-01</td>\n",
       "      <td>1995</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10.31</td>\n",
       "      <td>-69.83</td>\n",
       "      <td>training</td>\n",
       "      <td>2.290730</td>\n",
       "      <td>508.541046</td>\n",
       "      <td>1.841747</td>\n",
       "      <td>0.461907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cerro_saroche</td>\n",
       "      <td>1995-04-01</td>\n",
       "      <td>1995</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10.31</td>\n",
       "      <td>-69.83</td>\n",
       "      <td>training</td>\n",
       "      <td>1.064486</td>\n",
       "      <td>508.541046</td>\n",
       "      <td>1.174055</td>\n",
       "      <td>0.613882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cerro_saroche</td>\n",
       "      <td>1995-05-01</td>\n",
       "      <td>1995</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10.31</td>\n",
       "      <td>-69.83</td>\n",
       "      <td>training</td>\n",
       "      <td>1.114330</td>\n",
       "      <td>508.541046</td>\n",
       "      <td>1.151622</td>\n",
       "      <td>0.768852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cerro_saroche</td>\n",
       "      <td>1995-06-01</td>\n",
       "      <td>1995</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>10.31</td>\n",
       "      <td>-69.83</td>\n",
       "      <td>training</td>\n",
       "      <td>0.573345</td>\n",
       "      <td>508.541046</td>\n",
       "      <td>0.850688</td>\n",
       "      <td>0.908978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            park    periodo  year  month  id_point  latitud  longitud  \\\n",
       "0  cerro_saroche 1995-02-01  1995      2         1    10.31    -69.83   \n",
       "1  cerro_saroche 1995-03-01  1995      3         1    10.31    -69.83   \n",
       "2  cerro_saroche 1995-04-01  1995      4         1    10.31    -69.83   \n",
       "3  cerro_saroche 1995-05-01  1995      5         1    10.31    -69.83   \n",
       "4  cerro_saroche 1995-06-01  1995      6         1    10.31    -69.83   \n",
       "\n",
       "       type  precipitacion_mm  elevacion_media  precipitacion_narx  \\\n",
       "0  training          0.340843       508.541046            0.355879   \n",
       "1  training          2.290730       508.541046            1.841747   \n",
       "2  training          1.064486       508.541046            1.174055   \n",
       "3  training          1.114330       508.541046            1.151622   \n",
       "4  training          0.573345       508.541046            0.850688   \n",
       "\n",
       "   prediction_ann  \n",
       "0        0.332924  \n",
       "1        0.461907  \n",
       "2        0.613882  \n",
       "3        0.768852  \n",
       "4        0.908978  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_precipitacion = pd.read_pickle(f'./{park}/data/ann_precipitacion.pkl')\n",
    "pd_precipitacion = pd_precipitacion[['park', 'periodo', 'year', 'month', 'id_point', 'latitud', 'longitud',\n",
    "                                    'type', 'precipitacion_mm','elevacion_media', 'precipitacion_narx', 'prediction_ann']]\n",
    "\n",
    "pd_precipitacion.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>park</th>\n",
       "      <th>periodo</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>id_point</th>\n",
       "      <th>latitud</th>\n",
       "      <th>longitud</th>\n",
       "      <th>type</th>\n",
       "      <th>precipitacion_mm</th>\n",
       "      <th>elevacion_media</th>\n",
       "      <th>precipitacion_narx</th>\n",
       "      <th>prediction_ann</th>\n",
       "      <th>ndvi_media</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cerro_saroche</td>\n",
       "      <td>1995-02-01</td>\n",
       "      <td>1995</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10.31</td>\n",
       "      <td>-69.83</td>\n",
       "      <td>training</td>\n",
       "      <td>0.340843</td>\n",
       "      <td>508.541046</td>\n",
       "      <td>0.355879</td>\n",
       "      <td>0.332924</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cerro_saroche</td>\n",
       "      <td>1995-03-01</td>\n",
       "      <td>1995</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10.31</td>\n",
       "      <td>-69.83</td>\n",
       "      <td>training</td>\n",
       "      <td>2.290730</td>\n",
       "      <td>508.541046</td>\n",
       "      <td>1.841747</td>\n",
       "      <td>0.461907</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cerro_saroche</td>\n",
       "      <td>1995-04-01</td>\n",
       "      <td>1995</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10.31</td>\n",
       "      <td>-69.83</td>\n",
       "      <td>training</td>\n",
       "      <td>1.064486</td>\n",
       "      <td>508.541046</td>\n",
       "      <td>1.174055</td>\n",
       "      <td>0.613882</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cerro_saroche</td>\n",
       "      <td>1995-05-01</td>\n",
       "      <td>1995</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10.31</td>\n",
       "      <td>-69.83</td>\n",
       "      <td>training</td>\n",
       "      <td>1.114330</td>\n",
       "      <td>508.541046</td>\n",
       "      <td>1.151622</td>\n",
       "      <td>0.768852</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cerro_saroche</td>\n",
       "      <td>1995-06-01</td>\n",
       "      <td>1995</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>10.31</td>\n",
       "      <td>-69.83</td>\n",
       "      <td>training</td>\n",
       "      <td>0.573345</td>\n",
       "      <td>508.541046</td>\n",
       "      <td>0.850688</td>\n",
       "      <td>0.908978</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            park    periodo  year  month  id_point  latitud  longitud  \\\n",
       "0  cerro_saroche 1995-02-01  1995      2         1    10.31    -69.83   \n",
       "1  cerro_saroche 1995-03-01  1995      3         1    10.31    -69.83   \n",
       "2  cerro_saroche 1995-04-01  1995      4         1    10.31    -69.83   \n",
       "3  cerro_saroche 1995-05-01  1995      5         1    10.31    -69.83   \n",
       "4  cerro_saroche 1995-06-01  1995      6         1    10.31    -69.83   \n",
       "\n",
       "       type  precipitacion_mm  elevacion_media  precipitacion_narx  \\\n",
       "0  training          0.340843       508.541046            0.355879   \n",
       "1  training          2.290730       508.541046            1.841747   \n",
       "2  training          1.064486       508.541046            1.174055   \n",
       "3  training          1.114330       508.541046            1.151622   \n",
       "4  training          0.573345       508.541046            0.850688   \n",
       "\n",
       "   prediction_ann  ndvi_media  \n",
       "0        0.332924         NaN  \n",
       "1        0.461907         NaN  \n",
       "2        0.613882         NaN  \n",
       "3        0.768852         NaN  \n",
       "4        0.908978         NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_model = pd.merge(pd_precipitacion,pd_ndvi,\n",
    "                    on=['periodo','id_point','latitud','longitud'],\n",
    "                    how='left')\n",
    "\n",
    "pd_model.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando transformación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>park</th>\n",
       "      <th>periodo</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>id_point</th>\n",
       "      <th>latitud</th>\n",
       "      <th>longitud</th>\n",
       "      <th>type</th>\n",
       "      <th>precipitacion_mm</th>\n",
       "      <th>elevacion_media</th>\n",
       "      <th>precipitacion_narx</th>\n",
       "      <th>prediction_ann</th>\n",
       "      <th>ndvi_media</th>\n",
       "      <th>precipitation_ann_t</th>\n",
       "      <th>ndvi_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cerro_saroche</td>\n",
       "      <td>1995-02-01</td>\n",
       "      <td>1995</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10.31</td>\n",
       "      <td>-69.83</td>\n",
       "      <td>training</td>\n",
       "      <td>0.340843</td>\n",
       "      <td>508.541046</td>\n",
       "      <td>0.355879</td>\n",
       "      <td>0.332924</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.106312</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cerro_saroche</td>\n",
       "      <td>1995-03-01</td>\n",
       "      <td>1995</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10.31</td>\n",
       "      <td>-69.83</td>\n",
       "      <td>training</td>\n",
       "      <td>2.290730</td>\n",
       "      <td>508.541046</td>\n",
       "      <td>1.841747</td>\n",
       "      <td>0.461907</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.208914</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cerro_saroche</td>\n",
       "      <td>1995-04-01</td>\n",
       "      <td>1995</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10.31</td>\n",
       "      <td>-69.83</td>\n",
       "      <td>training</td>\n",
       "      <td>1.064486</td>\n",
       "      <td>508.541046</td>\n",
       "      <td>1.174055</td>\n",
       "      <td>0.613882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.329807</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cerro_saroche</td>\n",
       "      <td>1995-05-01</td>\n",
       "      <td>1995</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10.31</td>\n",
       "      <td>-69.83</td>\n",
       "      <td>training</td>\n",
       "      <td>1.114330</td>\n",
       "      <td>508.541046</td>\n",
       "      <td>1.151622</td>\n",
       "      <td>0.768852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.453081</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cerro_saroche</td>\n",
       "      <td>1995-06-01</td>\n",
       "      <td>1995</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>10.31</td>\n",
       "      <td>-69.83</td>\n",
       "      <td>training</td>\n",
       "      <td>0.573345</td>\n",
       "      <td>508.541046</td>\n",
       "      <td>0.850688</td>\n",
       "      <td>0.908978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.564548</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            park    periodo  year  month  id_point  latitud  longitud  \\\n",
       "0  cerro_saroche 1995-02-01  1995      2         1    10.31    -69.83   \n",
       "1  cerro_saroche 1995-03-01  1995      3         1    10.31    -69.83   \n",
       "2  cerro_saroche 1995-04-01  1995      4         1    10.31    -69.83   \n",
       "3  cerro_saroche 1995-05-01  1995      5         1    10.31    -69.83   \n",
       "4  cerro_saroche 1995-06-01  1995      6         1    10.31    -69.83   \n",
       "\n",
       "       type  precipitacion_mm  elevacion_media  precipitacion_narx  \\\n",
       "0  training          0.340843       508.541046            0.355879   \n",
       "1  training          2.290730       508.541046            1.841747   \n",
       "2  training          1.064486       508.541046            1.174055   \n",
       "3  training          1.114330       508.541046            1.151622   \n",
       "4  training          0.573345       508.541046            0.850688   \n",
       "\n",
       "   prediction_ann  ndvi_media  precipitation_ann_t  ndvi_t  \n",
       "0        0.332924         NaN             0.106312     NaN  \n",
       "1        0.461907         NaN             0.208914     NaN  \n",
       "2        0.613882         NaN             0.329807     NaN  \n",
       "3        0.768852         NaN             0.453081     NaN  \n",
       "4        0.908978         NaN             0.564548     NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformacion\n",
    "ndvi_transformacion = MinMaxScaler() #LogMinimax.create( pd_sst.oni.to_numpy() )\n",
    "ndvi_transformacion.fit(pd_model[['prediction_ann','ndvi_media']])\n",
    "\n",
    "pd_model[['precipitation_ann_t','ndvi_t']] = ndvi_transformacion.transform( pd_model[['prediction_ann','ndvi_media']] )\n",
    "pd_model.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directorio experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = f'./{park}/'\n",
    "experimento = f'experiments/narx/ndvi/{id_point}'\n",
    "\n",
    "try:\n",
    "    os.mkdir(f'{DIR}{experimento}')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ajustando modelo NARX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ndvi_t</th>\n",
       "      <th>precipitation_ann_t</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>periodo</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-01</th>\n",
       "      <td>0.810476</td>\n",
       "      <td>0.021764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-01</th>\n",
       "      <td>0.603212</td>\n",
       "      <td>0.091347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-01</th>\n",
       "      <td>0.393684</td>\n",
       "      <td>0.186584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-04-01</th>\n",
       "      <td>0.745203</td>\n",
       "      <td>0.299522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-01</th>\n",
       "      <td>0.941786</td>\n",
       "      <td>0.415524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ndvi_t  precipitation_ann_t\n",
       "periodo                                  \n",
       "2012-01-01  0.810476             0.021764\n",
       "2012-02-01  0.603212             0.091347\n",
       "2012-03-01  0.393684             0.186584\n",
       "2012-04-01  0.745203             0.299522\n",
       "2012-05-01  0.941786             0.415524"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_model_id = pd_model[pd_model.id_point==id_point]\n",
    "pd_model_id.index = pd.to_datetime(pd_model_id.periodo)\n",
    "pd_model_id = pd_model_id[[y_output,exogena]].dropna()\n",
    "pd_model_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(pd_model_id,exog_order,auto_order,exog_delay,prediction_order,exogena,y_output):\n",
    "    \"\"\"\n",
    "    Funcion para dale estructura a los datos\n",
    "    \"\"\"\n",
    "\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "\n",
    "    min_index = max([exog_order+exog_delay,auto_order])\n",
    "    index_split = pd_model_id[min_index:].index\n",
    "\n",
    "    for t in range(len(index_split)):\n",
    "\n",
    "        pd_to_split = pd_model_id[pd_model_id.index<=index_split[t]][-min_index-1:]\n",
    "\n",
    "        exogen_values = pd_to_split[(pd_to_split.shape[0]-exog_delay-exog_order):(pd_to_split.shape[0]-exog_delay)][[exogena]].values.reshape(-1)\n",
    "        auto_values = pd_to_split[-auto_order-1:][[y_output]].values.reshape(-1)\n",
    "\n",
    "        x_data.append(np.concatenate([exogen_values, auto_values[:-1]],axis=None))\n",
    "        y_data.append(auto_values[-1])\n",
    "        \n",
    "    x_data = np.array(x_data)\n",
    "    y_data = np.array(y_data)\n",
    "\n",
    "    return x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data, y_data = split_data(pd_model_id,exog_order,auto_order,exog_delay,prediction_order,exogena,y_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_data[:-prediction_order]\n",
    "x_vasl = x_data[-prediction_order:]\n",
    "\n",
    "y_train = y_data[:-prediction_order]\n",
    "y_vasl = y_data[-prediction_order:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo NARX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrícas\n",
    "mae = keras.metrics.MeanAbsoluteError()\n",
    "rmse = keras.metrics.RootMeanSquaredError()\n",
    "\n",
    "confi = {'Input':{'batch_size':None,\n",
    "                'name':'input',\n",
    "                'dtype':None,\n",
    "                'sparse':None,\n",
    "                'tensor':None,\n",
    "                'ragged':None,\n",
    "                'type_spec':None},\n",
    "        'Dense':{'use_bias':True,\n",
    "                'kernel_regularizer':None,\n",
    "                'bias_regularizer':None,\n",
    "                'activity_regularizer':None,\n",
    "                'kernel_constraint':None,\n",
    "                'bias_constraint':None\n",
    "                }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = int(2*x_train.shape[-1]/3)\n",
    "n_neurons = [int(3*total/6), int(2*total/6), int(1*total/6), 1]\n",
    "\n",
    "activation = len(n_neurons)*[f_activation]\n",
    "kernel_initializer = 'lecun_normal'\n",
    "bias_initializer = 'zeros'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "# Entradas\n",
    "model.add(keras.layers.Input(shape=(x_train.shape[-1],),\n",
    "                                    batch_size = confi.get('Input').get('batch_size'),\n",
    "                                    name = confi.get('Input').get('name'),\n",
    "                                    dtype = confi.get('Input').get('dtype'),\n",
    "                                    sparse = confi.get('Input').get('sparse'),\n",
    "                                    tensor = confi.get('Input').get('tensor'),\n",
    "                                    ragged = confi.get('Input').get('ragged'),\n",
    "                                    type_spec = confi.get('Input').get('type_spec')\n",
    "                                    ))\n",
    "\n",
    "model.add(keras.layers.Dense(   units=n_neurons[0],\n",
    "                                activation=activation[0],\n",
    "                                use_bias = confi.get('Dense').get('use_bias'),\n",
    "                                kernel_initializer=kernel_initializer,\n",
    "                                bias_initializer=bias_initializer,\n",
    "                                kernel_regularizer = confi.get('Dense').get('kernel_regularizer'),\n",
    "                                bias_regularizer = confi.get('Dense').get('bias_regularizer'),\n",
    "                                activity_regularizer = confi.get('Dense').get('activity_regularizer'),\n",
    "                                kernel_constraint = confi.get('Dense').get('kernel_constraint'),\n",
    "                                bias_constraint = confi.get('Dense').get('bias_constraint')\n",
    "                                ))\n",
    "                                \n",
    "model.add(keras.layers.Dropout(0.1))\n",
    "\n",
    "# Hidden Leyers\n",
    "if len(n_neurons)>1:\n",
    "    for index in list( range(1, len(n_neurons)) ):\n",
    "\n",
    "        model.add(keras.layers.Dense(   units=n_neurons[index],\n",
    "                                        activation=activation[index],\n",
    "                                        use_bias = confi.get('Dense').get('use_bias'),\n",
    "                                        kernel_initializer=kernel_initializer,\n",
    "                                        bias_initializer=bias_initializer,\n",
    "                                        kernel_regularizer = confi.get('Dense').get('kernel_regularizer'),\n",
    "                                        bias_regularizer = confi.get('Dense').get('bias_regularizer'),\n",
    "                                        activity_regularizer = confi.get('Dense').get('activity_regularizer'),\n",
    "                                        kernel_constraint = confi.get('Dense').get('kernel_constraint'),\n",
    "                                        bias_constraint = confi.get('Dense').get('bias_constraint')\n",
    "                                        ))\n",
    "                                        \n",
    "        # model.add(keras.layers.Dropout(0.001))\n",
    "        # print()\n",
    "\n",
    "# Out\n",
    "model.add(keras.layers.Dense(   units=1,\n",
    "                                activation='linear',\n",
    "                                kernel_initializer=kernel_initializer,\n",
    "                                bias_initializer=bias_initializer\n",
    "                                ))\n",
    "                                \n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=[mae,rmse]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = keras.callbacks.EarlyStopping(\n",
    "                                            monitor=\"loss\",\n",
    "                                            min_delta=0,\n",
    "                                            patience=patience,\n",
    "                                            verbose=0,\n",
    "                                            mode=\"min\",\n",
    "                                            baseline=None,\n",
    "                                            restore_best_weights=False,\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total epocas:214\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=x_train,\n",
    "                    y=y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=1,\n",
    "                    verbose=0,\n",
    "                    workers=2,\n",
    "                    callbacks=[callback])\n",
    "\n",
    "print(f'Total epocas:{len(history.epoch)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluación entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "trainPredict = model.predict(x_train, verbose=0).reshape(-1)\n",
    "testPredict = model.predict(x_vasl, verbose=0).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data de test\n",
    "trainind_pd = pd.DataFrame(trainPredict,\n",
    "                            index = pd_model_id[-(trainPredict.shape[0]+prediction_order):-(prediction_order)].index,\n",
    "                            columns=['prediction']\n",
    "                            )\n",
    "\n",
    "trainind_pd[y_output] = y_train.reshape(-1)\n",
    "trainind_pd['type'] = 'training'\n",
    "trainind_pd['precipitation_ann_t'] = np.nan\n",
    "\n",
    "trainind_pd['id_point'] = id_point\n",
    "\n",
    "trainind_pd[['prediction_ann','ndvi_prediction']] = ndvi_transformacion.inverse_transform(trainind_pd[['precipitation_ann_t','prediction']])\n",
    "trainind_pd[['prediction_ann','ndvi_media']] = ndvi_transformacion.inverse_transform(trainind_pd[['precipitation_ann_t',y_output]])\n",
    "\n",
    "trainind_pd = trainind_pd.reset_index(drop=False)[['id_point', 'periodo','type','ndvi_prediction','ndvi_media']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validacion entrenamiento\n",
    "trainig_metrics = metrics(observado=trainind_pd.ndvi_media,\n",
    "                          prediccion=trainind_pd.ndvi_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluación validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data de test\n",
    "validation_pd = pd.DataFrame(testPredict,\n",
    "                            index = pd_model_id[-prediction_order:].index,\n",
    "                            columns=['prediction']\n",
    "                            )\n",
    "\n",
    "validation_pd[y_output] = y_vasl.reshape(-1)\n",
    "validation_pd['type'] = 'validation'\n",
    "validation_pd['precipitation_ann_t'] = np.nan\n",
    "\n",
    "validation_pd['id_point'] = id_point\n",
    "\n",
    "validation_pd[['prediction_ann','ndvi_prediction']] = ndvi_transformacion.inverse_transform(validation_pd[['precipitation_ann_t','prediction']])\n",
    "validation_pd[['prediction_ann','ndvi_media']] = ndvi_transformacion.inverse_transform(validation_pd[['precipitation_ann_t',y_output]])\n",
    "\n",
    "validation_pd = validation_pd.reset_index(drop=False)[['id_point', 'periodo','type','ndvi_prediction','ndvi_media']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validacion entrenamiento\n",
    "validation_metrics = metrics(observado=validation_pd.ndvi_media,\n",
    "                          prediccion=validation_pd.ndvi_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sección Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one_stap_narx(model,data_predict,data_exogena,exog_order,auto_order,exog_delay,prediction_order,exogena,y_output):\n",
    "    \"\"\"\n",
    "    Funcion para predecir a un paso\n",
    "    \"\"\"\n",
    "    \n",
    "    data_proces = pd.concat([data_predict,data_exogena[list(data_predict)]])\n",
    "    data_proces['type'] = 'data_in'\n",
    "\n",
    "    date_min = data_proces[data_proces[y_output].isnull()].index.min()\n",
    "    date_max = data_proces[data_proces[y_output].isnull()].index.max()\n",
    "\n",
    "    date = date_min\n",
    "    while date <= date_max:\n",
    "        x_data_test, y_data_test = split_data(data_proces[data_proces.index<=date],\n",
    "                                                exog_order,\n",
    "                                                auto_order,\n",
    "                                                exog_delay,\n",
    "                                                prediction_order,\n",
    "                                                exogena,y_output)\n",
    "\n",
    "        predit = model.predict(x_data_test[-1].reshape(1, x_data_test.shape[1]), verbose=0).reshape(-1)\n",
    "        data_proces.loc[(data_proces.index==date),y_output]=predit\n",
    "\n",
    "        date = data_proces[data_proces[y_output].isnull()].index.min()\n",
    "\n",
    "    return data_proces[data_proces.index>=date_min]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_exogena = pd_model_id[-prediction_order:][[exogena]]\n",
    "data_exogena[y_output] = np.nan\n",
    "data_predict = pd_model_id[pd_model_id.index < data_exogena.index.min()][[y_output,exogena]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_test = predict_one_stap_narx(model,data_predict,data_exogena,exog_order,auto_order,exog_delay,prediction_order,exogena,y_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_test = predict_one_stap_narx(model,data_predict,data_exogena,exog_order,auto_order,exog_delay,prediction_order,exogena,y_output)\n",
    "\n",
    "pd_test = pd_test.rename(columns={y_output:'prediction'})\n",
    "pd_test['type'] = 'test'\n",
    "\n",
    "pd_test[y_output] = pd_model_id[pd_model_id.index > trainind_pd.periodo.max()][y_output]\n",
    "\n",
    "pd_test['id_point'] = id_point\n",
    "\n",
    "pd_test[['prediction_ann','ndvi_prediction']] = ndvi_transformacion.inverse_transform(pd_test[['precipitation_ann_t','prediction']])\n",
    "pd_test[['prediction_ann','ndvi_media']] = ndvi_transformacion.inverse_transform(pd_test[['precipitation_ann_t',y_output]])\n",
    "\n",
    "pd_test = pd_test.reset_index(drop=False)[['id_point', 'periodo','type','ndvi_prediction','ndvi_media']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validacion entrenamiento\n",
    "test_metrics = metrics(observado=pd_test.ndvi_media,\n",
    "                        prediccion=pd_test.ndvi_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados del modelo\n",
    "dict_metrics = {'epocas':[len(history.epoch)],\n",
    "                'prediction_order':[prediction_order],\n",
    "                'auto_order':[auto_order],\n",
    "                'exog_order':[exog_order],\n",
    "                'exog_delay':[exog_delay],\n",
    "                'activation':[activation[0]],\n",
    "                'id_point':[id_point],\n",
    "                'n_neurons':str(n_neurons),\n",
    "                'capas':[len(n_neurons)],\n",
    "                'training_mse':[trainig_metrics[\"mse\"]],\n",
    "                'training_rmse':[trainig_metrics[\"rmse\"]],\n",
    "                'training_mae':[trainig_metrics[\"mae\"]],\n",
    "                'trainig_mape':[trainig_metrics['mape']],\n",
    "                'trainig_r':[trainig_metrics['r2']],\n",
    "                'validation_mse':[validation_metrics[\"mse\"]],\n",
    "                'validation_rmse':[validation_metrics[\"rmse\"]],\n",
    "                'validation_mae':[validation_metrics[\"mae\"]],\n",
    "                'validation_mape':[validation_metrics['mape']],\n",
    "                'validation_r':[validation_metrics['r2']],\n",
    "                'test_mse':[test_metrics[\"mse\"]],\n",
    "                'test_rmse':[test_metrics[\"rmse\"]],\n",
    "                'test_mae':[test_metrics[\"mae\"]],\n",
    "                'test_mape':[test_metrics['mape']],\n",
    "                'test_r':[test_metrics['r2']]\n",
    "                }\n",
    "\n",
    "experimento_pd = pd.DataFrame.from_dict(dict_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pronóstico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_predict = pd_model_id[[y_output,exogena]]\n",
    "\n",
    "data_exogena = pd_model[(pd_model.periodo > data_predict.index.max()) & (pd_model.id_point==id_point)][[exogena,'periodo']]\n",
    "data_exogena.index = pd.to_datetime(data_exogena.periodo)\n",
    "data_exogena[y_output] = np.nan\n",
    "data_exogena = data_exogena.sort_index()[[exogena,y_output]]\n",
    "\n",
    "pd_prediction = predict_one_stap_narx(model,data_predict,data_exogena,exog_order,auto_order,exog_delay,prediction_order, exogena, y_output)\n",
    "pd_prediction = pd_prediction.rename(columns={y_output:'prediction'})\n",
    "pd_prediction['type'] = 'prediction'\n",
    "pd_prediction['id_point'] = id_point\n",
    "\n",
    "\n",
    "pd_prediction[['prediction_ann','ndvi_prediction']] = ndvi_transformacion.inverse_transform(pd_prediction[['precipitation_ann_t','prediction']])\n",
    "pd_prediction['ndvi_media'] = np.nan\n",
    "\n",
    "pd_prediction = pd_prediction.reset_index(drop=False)[['id_point', 'periodo','type','ndvi_prediction','ndvi_media']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniendo informacion\n",
    "pd_summary = pd.concat([trainind_pd[list(pd_prediction)], \n",
    "                        pd_test[list(pd_prediction)], \n",
    "                        validation_pd[list(pd_prediction)], \n",
    "                        pd_prediction[list(pd_prediction)]\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logica de guardado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: 0.2618402684383693; Best Model: 0.6129741623134988\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "if os.listdir(f'{DIR}{experimento}') == []:\n",
    "\n",
    "    # Modelo\n",
    "    model.save(f'{DIR}{experimento}/model.h5')\n",
    "\n",
    "    # Pesos\n",
    "    model.save_weights(f'{DIR}{experimento}/weights.h5')\n",
    "\n",
    "    # History\n",
    "    with open(f'{DIR}{experimento}/history.pkl', 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)\n",
    "    \n",
    "    # guardando resultados\n",
    "    pd_summary.to_pickle(f'{DIR}{experimento}/predicciones.pkl')\n",
    "\n",
    "else:\n",
    "    files = [x for x in os.listdir(f'{DIR}{experimento}') if x.find('summary')!=-1 ]\n",
    "    total_summary = pd.concat([pd.read_csv(f'{DIR}{experimento}/{file}') for file in files])\n",
    "    print( f\"Actual: {validation_metrics['r2']}; Best Model: {total_summary.validation_r.max()}\" )\n",
    "\n",
    "    if validation_metrics['r2'] > total_summary.validation_r.max(): \n",
    "\n",
    "        # Modelo\n",
    "        model.save(f'{DIR}{experimento}/model.h5')\n",
    "\n",
    "        # Pesos\n",
    "        model.save_weights(f'{DIR}{experimento}/weights.h5')\n",
    "\n",
    "        # History\n",
    "        with open(f'{DIR}{experimento}/history.pkl', 'wb') as file_pi:\n",
    "            pickle.dump(history.history, file_pi)\n",
    "        \n",
    "        # guardando resultados\n",
    "        pd_summary.to_pickle(f'{DIR}{experimento}/predicciones.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "experi = f'{DIR}{experimento}/{id_point}_{len(n_neurons)}_{activation[0]}_{prediction_order}_{auto_order}_{exog_order}_{exog_delay}'\n",
    "experimento_pd.to_csv(f'{experi}_summary.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('ssev_analytics')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7962acab993cb47be2d59fc45292cc4ac077641aa9e9bf66ffc44da07d377859"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
