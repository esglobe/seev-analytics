{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis Precipitación Total Parque Nacional Terepaima\n",
    "\n",
    "**PROYECTO:** SISTEMA PARA EL SEGUIMIENTO DE ECOSISTEMAS VENEZOLANOS \\\n",
    "**AUTOR:** Javier Martinez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directorio de trabajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Directorio actual:  /media/javier/Compartida/doctorado/ssev-analytics/terepaima\n",
      "> Directorio actual:  /media/javier/Compartida/doctorado/ssev-analytics\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print('> Directorio actual: ', os.getcwd())  \n",
    "os.chdir('../')\n",
    "print('> Directorio actual: ', os.getcwd()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.MONGO import CONEXION\n",
    "from utils.UTILS import *\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creando Coenxión con Mongo DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['estimateMeteorological', 'meteorological', 'estimateSSTNino34', 'SSTNino34']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creando la conexión con MongoDB\n",
    "db = CONEXION.conexion()\n",
    "db.list_collection_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descargando la Información Precipitación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parque\n",
    "park = 'terepaima'\n",
    "id_point = 1\n",
    "\n",
    "y_output = 'precip_t'\n",
    "exogena = 'oni'\n",
    "\n",
    "prediction_order = 12 # rango de prediccion\n",
    "auto_order = 20*12 # componente autoregresiva\n",
    "exog_order =  10*12# componente exogena qm\n",
    "exog_delay = 1# componente exogena dm\n",
    "\n",
    "f_activation = 'sigmoid'\n",
    "\n",
    "# Parametros de modelos\n",
    "patience = 15\n",
    "epochs=500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directorio del experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = f'./{park}/'\n",
    "experimento = f'experiments/narx/precipitacion/id_point_{id_point}'\n",
    "\n",
    "try:\n",
    "    os.mkdir(f'{DIR}{experimento}')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consulta de la data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizando consulta\n",
    "meteorological = db.meteorological.find({\"park\":park, 'id_point':id_point})\n",
    "\n",
    "# Generando pandas dataframe\n",
    "data_pandas = pd.DataFrame([file for file in meteorological])\n",
    "data_pandas['periodo'] = data_pandas.time.apply(lambda x: datetime.fromordinal(x))\n",
    "data_pandas['mes_year'] =  data_pandas['periodo'].dt.strftime('%B-%Y')\n",
    "data_pandas.index = pd.to_datetime(data_pandas.periodo)\n",
    "#data_pandas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>id_point</th>\n",
       "      <th>park</th>\n",
       "      <th>time</th>\n",
       "      <th>elevacion_maxima</th>\n",
       "      <th>elevacion_media</th>\n",
       "      <th>elevacion_mediana</th>\n",
       "      <th>latitud</th>\n",
       "      <th>longitud</th>\n",
       "      <th>ndvi_maxima</th>\n",
       "      <th>ndvi_media</th>\n",
       "      <th>ndvi_mediana</th>\n",
       "      <th>precipitacion_mm</th>\n",
       "      <th>time_actualizacion</th>\n",
       "      <th>periodo</th>\n",
       "      <th>mes_year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>periodo</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-01-01</th>\n",
       "      <td>63548350343c9f2921dbb11e</td>\n",
       "      <td>1</td>\n",
       "      <td>terepaima</td>\n",
       "      <td>719163</td>\n",
       "      <td>1632.0</td>\n",
       "      <td>1001.651794</td>\n",
       "      <td>986.0</td>\n",
       "      <td>9.96</td>\n",
       "      <td>-69.38</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.698088</td>\n",
       "      <td>738450</td>\n",
       "      <td>1970-01-01</td>\n",
       "      <td>January-1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-02-01</th>\n",
       "      <td>63548350343c9f2921dbb12a</td>\n",
       "      <td>1</td>\n",
       "      <td>terepaima</td>\n",
       "      <td>719194</td>\n",
       "      <td>1632.0</td>\n",
       "      <td>1001.651794</td>\n",
       "      <td>986.0</td>\n",
       "      <td>9.96</td>\n",
       "      <td>-69.38</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.460838</td>\n",
       "      <td>738450</td>\n",
       "      <td>1970-02-01</td>\n",
       "      <td>February-1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-03-01</th>\n",
       "      <td>63548350343c9f2921dbb147</td>\n",
       "      <td>1</td>\n",
       "      <td>terepaima</td>\n",
       "      <td>719222</td>\n",
       "      <td>1632.0</td>\n",
       "      <td>1001.651794</td>\n",
       "      <td>986.0</td>\n",
       "      <td>9.96</td>\n",
       "      <td>-69.38</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.559042</td>\n",
       "      <td>738450</td>\n",
       "      <td>1970-03-01</td>\n",
       "      <td>March-1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-04-01</th>\n",
       "      <td>63548350343c9f2921dbb165</td>\n",
       "      <td>1</td>\n",
       "      <td>terepaima</td>\n",
       "      <td>719253</td>\n",
       "      <td>1632.0</td>\n",
       "      <td>1001.651794</td>\n",
       "      <td>986.0</td>\n",
       "      <td>9.96</td>\n",
       "      <td>-69.38</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.815903</td>\n",
       "      <td>738450</td>\n",
       "      <td>1970-04-01</td>\n",
       "      <td>April-1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-05-01</th>\n",
       "      <td>63548350343c9f2921dbb174</td>\n",
       "      <td>1</td>\n",
       "      <td>terepaima</td>\n",
       "      <td>719283</td>\n",
       "      <td>1632.0</td>\n",
       "      <td>1001.651794</td>\n",
       "      <td>986.0</td>\n",
       "      <td>9.96</td>\n",
       "      <td>-69.38</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3.538272</td>\n",
       "      <td>738450</td>\n",
       "      <td>1970-05-01</td>\n",
       "      <td>May-1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01</th>\n",
       "      <td>6354837d343c9f2921dbe2a6</td>\n",
       "      <td>1</td>\n",
       "      <td>terepaima</td>\n",
       "      <td>738156</td>\n",
       "      <td>1632.0</td>\n",
       "      <td>1001.651794</td>\n",
       "      <td>986.0</td>\n",
       "      <td>9.96</td>\n",
       "      <td>-69.38</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.141664</td>\n",
       "      <td>738450</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>January-2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-01</th>\n",
       "      <td>6354837d343c9f2921dbe2c4</td>\n",
       "      <td>1</td>\n",
       "      <td>terepaima</td>\n",
       "      <td>738187</td>\n",
       "      <td>1632.0</td>\n",
       "      <td>1001.651794</td>\n",
       "      <td>986.0</td>\n",
       "      <td>9.96</td>\n",
       "      <td>-69.38</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.386378</td>\n",
       "      <td>738450</td>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>February-2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-01</th>\n",
       "      <td>6354837d343c9f2921dbe2d3</td>\n",
       "      <td>1</td>\n",
       "      <td>terepaima</td>\n",
       "      <td>738215</td>\n",
       "      <td>1632.0</td>\n",
       "      <td>1001.651794</td>\n",
       "      <td>986.0</td>\n",
       "      <td>9.96</td>\n",
       "      <td>-69.38</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.579085</td>\n",
       "      <td>738450</td>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>March-2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-01</th>\n",
       "      <td>6354837d343c9f2921dbe2e9</td>\n",
       "      <td>1</td>\n",
       "      <td>terepaima</td>\n",
       "      <td>738246</td>\n",
       "      <td>1632.0</td>\n",
       "      <td>1001.651794</td>\n",
       "      <td>986.0</td>\n",
       "      <td>9.96</td>\n",
       "      <td>-69.38</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.349987</td>\n",
       "      <td>738450</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>April-2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-01</th>\n",
       "      <td>6354837d343c9f2921dbe2fe</td>\n",
       "      <td>1</td>\n",
       "      <td>terepaima</td>\n",
       "      <td>738276</td>\n",
       "      <td>1632.0</td>\n",
       "      <td>1001.651794</td>\n",
       "      <td>986.0</td>\n",
       "      <td>9.96</td>\n",
       "      <td>-69.38</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.416590</td>\n",
       "      <td>738450</td>\n",
       "      <td>2022-05-01</td>\n",
       "      <td>May-2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>629 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 _id  id_point       park    time  \\\n",
       "periodo                                                             \n",
       "1970-01-01  63548350343c9f2921dbb11e         1  terepaima  719163   \n",
       "1970-02-01  63548350343c9f2921dbb12a         1  terepaima  719194   \n",
       "1970-03-01  63548350343c9f2921dbb147         1  terepaima  719222   \n",
       "1970-04-01  63548350343c9f2921dbb165         1  terepaima  719253   \n",
       "1970-05-01  63548350343c9f2921dbb174         1  terepaima  719283   \n",
       "...                              ...       ...        ...     ...   \n",
       "2022-01-01  6354837d343c9f2921dbe2a6         1  terepaima  738156   \n",
       "2022-02-01  6354837d343c9f2921dbe2c4         1  terepaima  738187   \n",
       "2022-03-01  6354837d343c9f2921dbe2d3         1  terepaima  738215   \n",
       "2022-04-01  6354837d343c9f2921dbe2e9         1  terepaima  738246   \n",
       "2022-05-01  6354837d343c9f2921dbe2fe         1  terepaima  738276   \n",
       "\n",
       "            elevacion_maxima  elevacion_media  elevacion_mediana  latitud  \\\n",
       "periodo                                                                     \n",
       "1970-01-01            1632.0      1001.651794              986.0     9.96   \n",
       "1970-02-01            1632.0      1001.651794              986.0     9.96   \n",
       "1970-03-01            1632.0      1001.651794              986.0     9.96   \n",
       "1970-04-01            1632.0      1001.651794              986.0     9.96   \n",
       "1970-05-01            1632.0      1001.651794              986.0     9.96   \n",
       "...                      ...              ...                ...      ...   \n",
       "2022-01-01            1632.0      1001.651794              986.0     9.96   \n",
       "2022-02-01            1632.0      1001.651794              986.0     9.96   \n",
       "2022-03-01            1632.0      1001.651794              986.0     9.96   \n",
       "2022-04-01            1632.0      1001.651794              986.0     9.96   \n",
       "2022-05-01            1632.0      1001.651794              986.0     9.96   \n",
       "\n",
       "            longitud ndvi_maxima ndvi_media ndvi_mediana  precipitacion_mm  \\\n",
       "periodo                                                                      \n",
       "1970-01-01    -69.38        None       None         None          1.698088   \n",
       "1970-02-01    -69.38        None       None         None          0.460838   \n",
       "1970-03-01    -69.38        None       None         None          0.559042   \n",
       "1970-04-01    -69.38        None       None         None          1.815903   \n",
       "1970-05-01    -69.38        None       None         None          3.538272   \n",
       "...              ...         ...        ...          ...               ...   \n",
       "2022-01-01    -69.38        None       None         None          0.141664   \n",
       "2022-02-01    -69.38        None       None         None          0.386378   \n",
       "2022-03-01    -69.38        None       None         None          0.579085   \n",
       "2022-04-01    -69.38        None       None         None          4.349987   \n",
       "2022-05-01    -69.38        None       None         None          1.416590   \n",
       "\n",
       "            time_actualizacion    periodo       mes_year  \n",
       "periodo                                                   \n",
       "1970-01-01              738450 1970-01-01   January-1970  \n",
       "1970-02-01              738450 1970-02-01  February-1970  \n",
       "1970-03-01              738450 1970-03-01     March-1970  \n",
       "1970-04-01              738450 1970-04-01     April-1970  \n",
       "1970-05-01              738450 1970-05-01       May-1970  \n",
       "...                        ...        ...            ...  \n",
       "2022-01-01              738450 2022-01-01   January-2022  \n",
       "2022-02-01              738450 2022-02-01  February-2022  \n",
       "2022-03-01              738450 2022-03-01     March-2022  \n",
       "2022-04-01              738450 2022-04-01     April-2022  \n",
       "2022-05-01              738450 2022-05-01       May-2022  \n",
       "\n",
       "[629 rows x 16 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estudio Precipitación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_precipitacion = data_pandas[['id_point', 'latitud', 'longitud',\n",
    "                                'precipitacion_mm']]\n",
    "#pd_precipitacion.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargando data SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizando consulta\n",
    "data_sst = db.estimateSSTNino34.find()\n",
    "\n",
    "# Generando pandas dataframe\n",
    "pd_sst = pd.DataFrame([file for file in data_sst])[['nino34_mean','oni','time']]\n",
    "pd_sst['periodo'] = pd_sst.time.apply(lambda x: datetime.fromordinal(x))\n",
    "pd_sst.index = pd.to_datetime(pd_sst.periodo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformacion\n",
    "oni_transformacion = MinMaxScaler() #LogMinimax.create( pd_sst.oni.to_numpy() )\n",
    "oni_transformacion.fit(pd_sst[['oni']])\n",
    "\n",
    "pd_sst['oni'] = oni_transformacion.transform( pd_sst[['oni']] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformacion\n",
    "sst_transformacion = LogMinimax.create( pd_sst.nino34_mean.to_numpy() )\n",
    "\n",
    "pd_sst['sst_t'] = sst_transformacion.transformacion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrando base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento\n",
    "pd_model = pd.merge(pd_precipitacion.reset_index(drop=False),pd_sst[['oni','sst_t']].reset_index(drop=False),\n",
    "                    on=['periodo'],\n",
    "                    how='left'\n",
    "                    )\n",
    "\n",
    "# Pronostico\n",
    "pd_sst_pron = pd_sst[['periodo','oni','sst_t']][pd_sst.periodo > pd_model.periodo.max()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>periodo</th>\n",
       "      <th>id_point</th>\n",
       "      <th>latitud</th>\n",
       "      <th>longitud</th>\n",
       "      <th>precipitacion_mm</th>\n",
       "      <th>oni</th>\n",
       "      <th>sst_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1970-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>9.96</td>\n",
       "      <td>-69.38</td>\n",
       "      <td>1.698088</td>\n",
       "      <td>0.543835</td>\n",
       "      <td>0.526009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1970-02-01</td>\n",
       "      <td>1</td>\n",
       "      <td>9.96</td>\n",
       "      <td>-69.38</td>\n",
       "      <td>0.460838</td>\n",
       "      <td>0.506771</td>\n",
       "      <td>0.549133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1970-03-01</td>\n",
       "      <td>1</td>\n",
       "      <td>9.96</td>\n",
       "      <td>-69.38</td>\n",
       "      <td>0.559042</td>\n",
       "      <td>0.497505</td>\n",
       "      <td>0.585536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1970-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>9.96</td>\n",
       "      <td>-69.38</td>\n",
       "      <td>1.815903</td>\n",
       "      <td>0.476123</td>\n",
       "      <td>0.698842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1970-05-01</td>\n",
       "      <td>1</td>\n",
       "      <td>9.96</td>\n",
       "      <td>-69.38</td>\n",
       "      <td>3.538272</td>\n",
       "      <td>0.444048</td>\n",
       "      <td>0.676378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>9.96</td>\n",
       "      <td>-69.38</td>\n",
       "      <td>0.141664</td>\n",
       "      <td>0.228083</td>\n",
       "      <td>0.280822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>1</td>\n",
       "      <td>9.96</td>\n",
       "      <td>-69.38</td>\n",
       "      <td>0.386378</td>\n",
       "      <td>0.234498</td>\n",
       "      <td>0.335206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>1</td>\n",
       "      <td>9.96</td>\n",
       "      <td>-69.38</td>\n",
       "      <td>0.579085</td>\n",
       "      <td>0.222381</td>\n",
       "      <td>0.424597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>9.96</td>\n",
       "      <td>-69.38</td>\n",
       "      <td>4.349987</td>\n",
       "      <td>0.205987</td>\n",
       "      <td>0.500842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>2022-05-01</td>\n",
       "      <td>1</td>\n",
       "      <td>9.96</td>\n",
       "      <td>-69.38</td>\n",
       "      <td>1.416590</td>\n",
       "      <td>0.220242</td>\n",
       "      <td>0.522145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>629 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       periodo  id_point  latitud  longitud  precipitacion_mm       oni  \\\n",
       "0   1970-01-01         1     9.96    -69.38          1.698088  0.543835   \n",
       "1   1970-02-01         1     9.96    -69.38          0.460838  0.506771   \n",
       "2   1970-03-01         1     9.96    -69.38          0.559042  0.497505   \n",
       "3   1970-04-01         1     9.96    -69.38          1.815903  0.476123   \n",
       "4   1970-05-01         1     9.96    -69.38          3.538272  0.444048   \n",
       "..         ...       ...      ...       ...               ...       ...   \n",
       "624 2022-01-01         1     9.96    -69.38          0.141664  0.228083   \n",
       "625 2022-02-01         1     9.96    -69.38          0.386378  0.234498   \n",
       "626 2022-03-01         1     9.96    -69.38          0.579085  0.222381   \n",
       "627 2022-04-01         1     9.96    -69.38          4.349987  0.205987   \n",
       "628 2022-05-01         1     9.96    -69.38          1.416590  0.220242   \n",
       "\n",
       "        sst_t  \n",
       "0    0.526009  \n",
       "1    0.549133  \n",
       "2    0.585536  \n",
       "3    0.698842  \n",
       "4    0.676378  \n",
       "..        ...  \n",
       "624  0.280822  \n",
       "625  0.335206  \n",
       "626  0.424597  \n",
       "627  0.500842  \n",
       "628  0.522145  \n",
       "\n",
       "[629 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ajustando modelo NARX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformacion\n",
    "transformacion = LogMinimax.create( pd_precipitacion.precipitacion_mm.to_numpy() )\n",
    "\n",
    "pd_model['precip_t'] = transformacion.transformacion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo según ID point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_model_id = pd_model[pd_model.id_point==id_point]\n",
    "pd_model_id.index = pd.to_datetime(pd_model_id.periodo)\n",
    "pd_model_id = pd_model_id[[y_output,exogena]]\n",
    "\n",
    "#pd_model_id.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiendo estructura de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data, y_data = split_data(pd_model_id,exog_order,auto_order,exog_delay,prediction_order,exogena,y_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_data[:-prediction_order]\n",
    "x_vasl = x_data[-prediction_order:]\n",
    "\n",
    "y_train = y_data[:-prediction_order]\n",
    "y_vasl = y_data[-prediction_order:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo NARX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrícas\n",
    "mae = keras.metrics.MeanAbsoluteError()\n",
    "rmse = keras.metrics.RootMeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "confi = {'Input':{'batch_size':None,\n",
    "                'name':'input',\n",
    "                'dtype':None,\n",
    "                'sparse':None,\n",
    "                'tensor':None,\n",
    "                'ragged':None,\n",
    "                'type_spec':None},\n",
    "        'Dense':{'use_bias':True,\n",
    "                'kernel_regularizer':None,\n",
    "                'bias_regularizer':None,\n",
    "                'activity_regularizer':None,\n",
    "                'kernel_constraint':None,\n",
    "                'bias_constraint':None\n",
    "                }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = int(2*x_train.shape[-1]/3)\n",
    "n_neurons = [int(3*total/6), int(2*total/6), int(1*total/6), 1]\n",
    "\n",
    "activation = len(n_neurons)*[f_activation]\n",
    "kernel_initializer = 'lecun_normal'\n",
    "bias_initializer = 'zeros'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "# Entradas\n",
    "model.add(keras.layers.Input(shape=(x_train.shape[-1],),\n",
    "                                    batch_size = confi.get('Input').get('batch_size'),\n",
    "                                    name = confi.get('Input').get('name'),\n",
    "                                    dtype = confi.get('Input').get('dtype'),\n",
    "                                    sparse = confi.get('Input').get('sparse'),\n",
    "                                    tensor = confi.get('Input').get('tensor'),\n",
    "                                    ragged = confi.get('Input').get('ragged'),\n",
    "                                    type_spec = confi.get('Input').get('type_spec')\n",
    "                                    ))\n",
    "\n",
    "model.add(keras.layers.Dense(   units=n_neurons[0],\n",
    "                                activation=activation[0],\n",
    "                                use_bias = confi.get('Dense').get('use_bias'),\n",
    "                                kernel_initializer=kernel_initializer,\n",
    "                                bias_initializer=bias_initializer,\n",
    "                                kernel_regularizer = confi.get('Dense').get('kernel_regularizer'),\n",
    "                                bias_regularizer = confi.get('Dense').get('bias_regularizer'),\n",
    "                                activity_regularizer = confi.get('Dense').get('activity_regularizer'),\n",
    "                                kernel_constraint = confi.get('Dense').get('kernel_constraint'),\n",
    "                                bias_constraint = confi.get('Dense').get('bias_constraint')\n",
    "                                ))\n",
    "                                \n",
    "model.add(keras.layers.Dropout(0.1))\n",
    "\n",
    "# Hidden Leyers\n",
    "if len(n_neurons)>1:\n",
    "    for index in list( range(1, len(n_neurons)) ):\n",
    "\n",
    "        model.add(keras.layers.Dense(   units=n_neurons[index],\n",
    "                                        activation=activation[index],\n",
    "                                        use_bias = confi.get('Dense').get('use_bias'),\n",
    "                                        kernel_initializer=kernel_initializer,\n",
    "                                        bias_initializer=bias_initializer,\n",
    "                                        kernel_regularizer = confi.get('Dense').get('kernel_regularizer'),\n",
    "                                        bias_regularizer = confi.get('Dense').get('bias_regularizer'),\n",
    "                                        activity_regularizer = confi.get('Dense').get('activity_regularizer'),\n",
    "                                        kernel_constraint = confi.get('Dense').get('kernel_constraint'),\n",
    "                                        bias_constraint = confi.get('Dense').get('bias_constraint')\n",
    "                                        ))\n",
    "                                        \n",
    "        # model.add(keras.layers.Dropout(0.001))\n",
    "        # print()\n",
    "\n",
    "# Out\n",
    "model.add(keras.layers.Dense(   units=1,\n",
    "                                activation='linear',\n",
    "                                kernel_initializer=kernel_initializer,\n",
    "                                bias_initializer=bias_initializer\n",
    "                                ))\n",
    "                                \n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=[mae,rmse]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = keras.callbacks.EarlyStopping(\n",
    "                                            monitor=\"loss\",\n",
    "                                            min_delta=0,\n",
    "                                            patience=patience,\n",
    "                                            verbose=0,\n",
    "                                            mode=\"min\",\n",
    "                                            baseline=None,\n",
    "                                            restore_best_weights=False,\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x=x_train,\n",
    "                    y=y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=1,\n",
    "                    verbose=0,\n",
    "                    workers=2,\n",
    "                    callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total epocas:23\n"
     ]
    }
   ],
   "source": [
    "print(f'Total epocas:{len(history.epoch)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluación entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "trainPredict = model.predict(x_train, verbose=0).reshape(-1)\n",
    "testPredict = model.predict(x_vasl, verbose=0).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data de test\n",
    "trainind_pd = pd.DataFrame(trainPredict,\n",
    "                            index = pd_model_id[-(trainPredict.shape[0]+prediction_order):-(prediction_order)].index,\n",
    "                            columns=['prediction']\n",
    "                            )\n",
    "\n",
    "trainind_pd[y_output] = y_train.reshape(-1)\n",
    "trainind_pd['type'] = 'training'\n",
    "\n",
    "trainind_pd['precipitacion_mm'] = trainind_pd[y_output].apply(lambda x: transformacion.inversa(x) if np.isnan(x)==False else np.nan )\n",
    "trainind_pd['prediction_precipitacion_mm'] = trainind_pd['prediction'].apply(lambda x: transformacion.inversa(x) if np.isnan(x)==False else np.nan )\n",
    "\n",
    "trainind_pd = pd.merge(trainind_pd,pd_model_id[[exogena]].reset_index(drop=False),\n",
    "                        on=['periodo'],\n",
    "                        how='left')\n",
    "\n",
    "trainind_pd.index = pd.to_datetime(trainind_pd.periodo)\n",
    "\n",
    "# Validacion entrenamiento\n",
    "trainig_metrics = metrics(observado=trainind_pd.precipitacion_mm,\n",
    "                          prediccion=trainind_pd.prediction_precipitacion_mm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluación validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data de Validacion\n",
    "validation_pd = pd.DataFrame(testPredict,\n",
    "                            index = pd_model_id[-prediction_order:].index,\n",
    "                            columns=['prediction']\n",
    "                            )\n",
    "\n",
    "validation_pd[y_output] = y_vasl.reshape(-1)\n",
    "validation_pd['type'] = 'validation'\n",
    "\n",
    "validation_pd['precipitacion_mm'] = validation_pd[y_output].apply(lambda x: transformacion.inversa(x) if np.isnan(x)==False else np.nan )\n",
    "validation_pd['prediction_precipitacion_mm'] = validation_pd['prediction'].apply(lambda x: transformacion.inversa(x) if np.isnan(x)==False else np.nan )\n",
    "\n",
    "validation_pd = pd.merge(validation_pd,pd_model_id[[exogena]].reset_index(drop=False),\n",
    "                        on=['periodo'],\n",
    "                        how='left')\n",
    "\n",
    "# Validacion entrenamiento\n",
    "validation_metrics = metrics(observado=validation_pd.precipitacion_mm,\n",
    "                          prediccion=validation_pd.prediction_precipitacion_mm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_exogena = pd_model_id[-prediction_order:][[exogena]]\n",
    "data_exogena[y_output] = np.nan\n",
    "data_predict = pd_model_id[pd_model_id.index < data_exogena.index.min()][[y_output,exogena]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mape': 189.01612160724622,\n",
       " 'mae': 1.0871622331000894,\n",
       " 'mse': 1.2811772231641188,\n",
       " 'rmse': 1.6414150771545222,\n",
       " 'r2': -0.0010289286103450923}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_test = predict_one_stap_narx(model,data_predict,data_exogena,exog_order,auto_order,exog_delay,prediction_order,exogena,y_output)\n",
    "\n",
    "pd_test = pd_test.rename(columns={y_output:'prediction'})\n",
    "pd_test['type'] = 'test'\n",
    "\n",
    "pd_test['precip_t'] = pd_model_id[pd_model_id.index > trainind_pd.periodo.max()][y_output]\n",
    "\n",
    "pd_test['precipitacion_mm'] = pd_test[y_output].apply(lambda x: transformacion.inversa(x) if np.isnan(x)==False else np.nan )\n",
    "pd_test['prediction_precipitacion_mm'] = pd_test['prediction'].apply(lambda x: transformacion.inversa(x) if np.isnan(x)==False else np.nan )\n",
    "\n",
    "# Validacion entrenamiento\n",
    "test_metrics = metrics(observado=pd_test.precipitacion_mm,\n",
    "                        prediccion=pd_test.prediction_precipitacion_mm)\n",
    "test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados del modelo\n",
    "dict_metrics = {'epocas':[len(history.epoch)],\n",
    "                'prediction_order':[prediction_order],\n",
    "                'auto_order':[auto_order],\n",
    "                'exog_order':[exog_order],\n",
    "                'exog_delay':[exog_delay],\n",
    "                'activation':[activation[0]],\n",
    "                'id_point':[id_point],\n",
    "                'n_neurons':str(n_neurons),\n",
    "                'capas':[len(n_neurons)],\n",
    "                'training_mse':[trainig_metrics[\"mse\"]],\n",
    "                'training_rmse':[trainig_metrics[\"rmse\"]],\n",
    "                'training_mae':[trainig_metrics[\"mae\"]],\n",
    "                'trainig_mape':[trainig_metrics['mape']],\n",
    "                'trainig_r':[trainig_metrics['r2']],\n",
    "                'validation_mse':[validation_metrics[\"mse\"]],\n",
    "                'validation_rmse':[validation_metrics[\"rmse\"]],\n",
    "                'validation_mae':[validation_metrics[\"mae\"]],\n",
    "                'validation_mape':[validation_metrics['mape']],\n",
    "                'validation_r':[validation_metrics['r2']],\n",
    "                'test_mse':[test_metrics[\"mse\"]],\n",
    "                'test_rmse':[test_metrics[\"rmse\"]],\n",
    "                'test_mae':[test_metrics[\"mae\"]],\n",
    "                'test_mape':[test_metrics['mape']],\n",
    "                'test_r':[test_metrics['r2']]\n",
    "                }\n",
    "\n",
    "experimento_pd = pd.DataFrame.from_dict(dict_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pronóstico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_predict = pd_model_id[[y_output,exogena]]\n",
    "\n",
    "data_exogena = pd_sst_pron[pd_sst_pron.index>data_predict.index.max()][[exogena]]\n",
    "data_exogena[y_output] = np.nan\n",
    "data_exogena = data_exogena[[y_output,exogena]]\n",
    "\n",
    "pd_prediction = predict_one_stap_narx(model,data_predict,data_exogena,exog_order,auto_order,exog_delay,prediction_order, exogena, y_output)\n",
    "\n",
    "pd_prediction = pd_prediction.rename(columns={y_output:'prediction'})\n",
    "pd_prediction['type'] = 'prediction'\n",
    "\n",
    "pd_prediction['precipitacion_mm'] = np.nan\n",
    "pd_prediction['prediction_precipitacion_mm'] = pd_prediction['prediction'].apply(lambda x: transformacion.inversa(x) if np.isnan(x)==False else np.nan )\n",
    "\n",
    "pd_prediction['precip_t'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['periodo', 'prediction', 'oni', 'type', 'precipitacion_mm', 'prediction_precipitacion_mm', 'precip_t']\n"
     ]
    }
   ],
   "source": [
    "columns = list(pd_prediction.reset_index(drop=False))\n",
    "print(columns)\n",
    "# Uniendo informacion\n",
    "pd_summary = pd.concat([trainind_pd.reset_index(drop=True)[columns], \n",
    "                        pd_test.reset_index(drop=False)[columns], \n",
    "                        validation_pd[columns], \n",
    "                        pd_prediction.reset_index(drop=False)[columns]\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['training', 'test', 'validation', 'prediction'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_summary.type.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logica de guardado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_confi = {\"id_point\":id_point,\n",
    "            \"n_neurons\":n_neurons,\n",
    "            \"activation\":activation,\n",
    "            \"prediction_order\":prediction_order,\n",
    "            \"auto_order\":auto_order,\n",
    "            \"exog_order\":exog_order,\n",
    "            \"exog_delay\":exog_delay,\n",
    "            \"metrics\":dict_metrics\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "if os.listdir(f'{DIR}{experimento}') == []:\n",
    "\n",
    "    # Modelo\n",
    "    model.save(f'{DIR}{experimento}/model.h5')\n",
    "\n",
    "    # Pesos\n",
    "    model.save_weights(f'{DIR}{experimento}/weights.h5')\n",
    "\n",
    "    # History\n",
    "    with open(f'{DIR}{experimento}/history.pkl', 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)\n",
    "\n",
    "    # confi\n",
    "    with open(f'{DIR}{experimento}/model_confi.pkl', 'wb') as file_pi:\n",
    "        pickle.dump(model_confi, file_pi)\n",
    "    \n",
    "    # guardando resultados\n",
    "    pd_summary.to_pickle(f'{DIR}{experimento}/predicciones.pkl')\n",
    "\n",
    "else:\n",
    "    files = [x for x in os.listdir(f'{DIR}{experimento}') if x.find('summary')!=-1 ]\n",
    "    total_summary = pd.concat([pd.read_csv(f'{DIR}{experimento}/{file}') for file in files])\n",
    "    print( f\"Actual: {validation_metrics['r2']}; Best Model: {total_summary.validation_r.max()}\" )\n",
    "\n",
    "    if validation_metrics['r2'] > total_summary.validation_r.max(): \n",
    "\n",
    "        # Modelo\n",
    "        model.save(f'{DIR}{experimento}/model.h5')\n",
    "\n",
    "        # Pesos\n",
    "        model.save_weights(f'{DIR}{experimento}/weights.h5')\n",
    "\n",
    "        # History\n",
    "        with open(f'{DIR}{experimento}/history.pkl', 'wb') as file_pi:\n",
    "            pickle.dump(history.history, file_pi)\n",
    "        \n",
    "        # confi\n",
    "        with open(f'{DIR}{experimento}/model_confi.pkl', 'wb') as file_pi:\n",
    "            pickle.dump(model_confi, file_pi)\n",
    "        \n",
    "        # guardando resultados\n",
    "        pd_summary.to_pickle(f'{DIR}{experimento}/predicciones.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardando Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "experi = f'{DIR}{experimento}/{id_point}_{len(n_neurons)}_{activation[0]}_{prediction_order}_{auto_order}_{exog_order}_{exog_delay}'\n",
    "experimento_pd.to_csv(f'{experi}_summary.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('ssev_analytics')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7962acab993cb47be2d59fc45292cc4ac077641aa9e9bf66ffc44da07d377859"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
